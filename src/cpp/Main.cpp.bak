#include <atomic>
#include <chrono>
#include <condition_variable>
#include <csignal>
#include <cstdlib>
#include <string>
#include <filesystem>

#include <thread>
#include <mutex>
#include <queue>

#include <dv-processing/core/core.hpp>
#include <dv-processing/core/stereo_event_stream_slicer.hpp>
#include <dv-processing/io/camera/discovery.hpp>
#include <dv-processing/io/camera/sync_camera_input_base.hpp>
#include <dv-processing/io/stereo_camera_writer.hpp>
#include <dv-processing/visualization/event_visualizer.hpp>

#include <opencv2/highgui.hpp>
#include "Log.h"

void logUsage(char* argv[]);

static std::atomic<bool> stopSignalDetection(false);

static void signalHandler(int)
{
	stopSignalDetection.store(true);
}

struct StereoBatch {
    std::shared_ptr<const dv::EventStore> left;
    std::shared_ptr<const dv::EventStore> right;
};

int capture(const std::filesystem::path &path, bool showVisualization)
{

	std::signal(SIGINT, signalHandler);
	std::signal(SIGTERM, signalHandler);
	
	auto cameras = dv::io::camera::discover();

	const size_t num_cameras = cameras.size();
	
	if(num_cameras != 2)
		throw dv::exceptions::RuntimeError("Unable to discover two cameras");

	Log::info("Found ", num_cameras, " cameras!");

	Log::info("Camera ", 0, ": ", cameras[0].cameraModel, "_", cameras[0].serialNumber);
	Log::info("Camera ", 1, ": ", cameras[1].cameraModel, "_", cameras[1].serialNumber);

	auto leftCamera = dv::io::camera::openSync(cameras[0]);
	auto rightCamera = dv::io::camera::openSync(cameras[1]);
	
	dv::io::camera::synchronizeAnyTwo(leftCamera, rightCamera);

	if(leftCamera->isMaster())
		Log::info("The left camera is clock syncronization master");
	else if (rightCamera->isMaster())	
		Log::info("The right camera is clock syncronization master");
	else
		throw dv::exceptions::RuntimeError("No clock syncronization master was detected");


	auto out = path / "stereo_recording.aedat4";
	dv::io::StereoCameraWriter writer(out.string(), *leftCamera, *rightCamera);

	std::queue<StereoBatch> visQueue;
	std::mutex queueMutex;

	std::condition_variable visQueueCondition;

	std::thread visThread([&]() {

		dv::StereoEventStreamSlicer slicer;

		dv::visualization::EventVisualizer leftVis(leftCamera->getEventResolution().value());
		dv::visualization::EventVisualizer rightVis(rightCamera->getEventResolution().value());

		if (showVisualization)
		{
			cv::namedWindow("Left", cv::WINDOW_NORMAL);
			cv::namedWindow("Right", cv::WINDOW_NORMAL);
		}
		// https://gitlab.com/inivation/dv/dv-processing/-/blob/master/samples/io/stereo-capture/stereo-capture.cpp
		slicer.doEveryTimeInterval(std::chrono::milliseconds{33},
			// Here we receive events from two camera, time-synchronized
			[&](const dv::EventStore &leftEvents, const dv::EventStore &rightEvents) {
				if (showVisualization)
				{
					// Perform visualization and show preview
					cv::imshow("Left", leftVis.generateImage(leftEvents));
					cv::imshow("Right", rightVis.generateImage(rightEvents));

					// Signal exit if ESC or "q" key is pressed
					char key = (char) cv::waitKey(1);
					if (key == 27 || key == 'q'){
						stopSignalDetection.store(true);
						// wake up thread
						visQueueCondition.notify_all();
					}
				}
		});
		// consumer
		while(!stopSignalDetection.load()) {
			StereoBatch batch;
			
			// use unique lock instead of scoped lock for dynamic locking and
			std::unique_lock<std::mutex> lock(queueMutex);

			// sleep here, release until a) sleepSignal = true or b) visQueue it
			// not empty (data arrived)
			visQueueCondition.wait(lock, [&]{ 
                return stopSignalDetection.load() || !visQueue.empty(); 
            });

			// if stopped and queue is empty -> done
			if (stopSignalDetection.load() && visQueue.empty()) {
                break;
            }

			// we have data
			batch = visQueue.front();
            visQueue.pop();

			// unlock here so that the main thread can push data while slicer is
			// processing
			lock.unlock(); 

            if (batch.left && batch.right) {
                slicer.accept(*batch.left, *batch.right);
            }
		}

		// thread finished, cleanup
		if (showVisualization) cv::destroyAllWindows();
	});

   
	Log::info("Starting the recording!");	
	while (!stopSignalDetection.load() && leftCamera->isRunning() && rightCamera->isRunning())
	{
		// For each of the available streams try readin a packet and write
		// immediately to a file	
		if (leftCamera->isEventStreamAvailable() && rightCamera->isEventStreamAvailable())
		{
			// not finished! https://chatgpt.com/c/694094f4-c4e8-832d-b573-8a70ccfcca8b
			// changed from const reference for moving
			auto leftEvents = leftCamera->getNextEventBatch();
			auto rightEvents = rightCamera->getNextEventBatch();

			if (leftEvents.has_value() && rightEvents.has_value())
			{
				auto lPtr = std::make_shared<dv::EventStore>(std::move(*leftEvents)); 
				auto rPtr = std::make_shared<dv::EventStore>(std::move(*rightEvents));

				writer.left.writeEvents(*lPtr); 
				writer.right.writeEvents(*rPtr);

				// producer (main thread)
				if (showVisualization) 
				{
					// lock, copy on queue, unlock
					std::scoped_lock lock(queueMutex);
					
					// limit queue size so memory stays concise (skip
					// visualization frame)
					if (visQueue.size() < 200)
						visQueue.push({lPtr, rPtr});

                } // scoped lock automatically releases here
				
				// notify the sleeping threas that there is data to process
                visQueueCondition.notify_one();
			}
		}
		if (leftCamera->isFrameStreamAvailable() && rightCamera->isFrameStreamAvailable())
		{
			const auto &leftFrame = leftCamera->getNextFrame();
			const auto &rightFrame = rightCamera->getNextFrame();
			if (leftFrame.has_value() && rightFrame.has_value())
			{
				writer.left.writeFrame(*leftFrame); 
				writer.right.writeFrame(*rightFrame);
			}
		}
		if (leftCamera->isImuStreamAvailable() && rightCamera->isImuStreamAvailable())
		{
			const auto &leftImu = leftCamera->getNextImuBatch();
			const auto &rightImu = rightCamera->getNextImuBatch();
			if (leftImu.has_value() && rightImu.has_value())
			{
				writer.left.writeImuPacket(*leftImu); 
				writer.right.writeImuPacket(*rightImu);
			}
		}
		if (leftCamera->isTriggerStreamAvailable() && rightCamera->isTriggerStreamAvailable())
		{
			const auto &leftTriggers = leftCamera->getNextTriggerBatch();
			const auto &rightTriggers = rightCamera->getNextTriggerBatch();
			if (leftTriggers.has_value() && rightTriggers.has_value())
			{
				writer.left.writeTriggerPacket(*leftTriggers); 
				writer.right.writeTriggerPacket(*rightTriggers);
			}
		}
	}

	Log::info("Finalizing the recording!");
	
    // ensure the thread isn't sleeping forever waiting for a packet that will never come
    stopSignalDetection.store(true);
    visQueueCondition.notify_all(); 
	
	// wait for second thread to finish before exiting
	if (visThread.joinable())
		visThread.join();

	return EXIT_SUCCESS;

}

int environment_installed()
{
	// TODO change the way the path is handled here (maybe using make install
	// later)
	int result = system(SCRIPTS_DIR "check_env.sh");	
	int exit_code = 0;
    if (WIFEXITED(result)) 
	{
        exit_code = WEXITSTATUS(result);
    }
    if (exit_code == 0) 
	{
        Log::info("Environment found.");
		return EXIT_SUCCESS;
    } 
	else if (exit_code == 1) 
	{
        Log::error("Environment E2VID missing.");
		return EXIT_FAILURE;
    } 
	else 
	{
        Log::error("Conda missing or Script not found (Exit code: ", exit_code, ")");
		return EXIT_FAILURE;
	}	
    
	return EXIT_FAILURE;
}

// int convertAedat4ToTxt(const std::filesystem::path& inputAedat4, const std::filesystem::path& outputVideoPath)
// {
// 	return EXIT_SUCCESS;
// }

int main (int argc, char *argv[])
{
	if (argc < 2)
	{
		logUsage(argv);
		return EXIT_FAILURE;
	}
	const std::string command = argv[1];
	if (command == "calibrate")
	{
		environment_installed();	
	}
	else if (command == "capture")
	{		
		std::string pathString;
		bool visualize = false;
		for (int i = 2; i < argc; ++i)
		{
			std::string arg = argv[i];

			if(arg == "-v" || arg == "--visualize") 
				visualize = true;

			else if (arg == "-p" || arg == "--path")
			{
            	if (i + 1 < argc) 
					pathString = argv[++i]; 
				else 
				{
					Log::error("Error: ", arg," flag requires a path argument.");
                    logUsage(argv);
                    return EXIT_FAILURE;		
				}
			}
		}
		
		if (pathString.empty())
		{
			Log::error("Error: Path not specified.");
			logUsage(argv);
			return EXIT_FAILURE;
		}

		const char* captureFolderName = "recordings";

		std::filesystem::path Location(pathString);
		std::filesystem::path fullPath = Location / captureFolderName;
		Log::info("The recording sessions will be saved under ", fullPath.string());
		if (visualize) 
			Log::info("Visualization enabled.");

		if(!std::filesystem::exists(fullPath))
		{	
			Log::warn("The provided path ", fullPath.string(), " does not exist. Do you want to create it? [Y/n]");

			const char response = (char)std::cin.get();
			if (response == '\n' || response == 'Y' || response == 'y')
			{
				Log::info("Creating path: ", fullPath.string());    
                try {
                    std::filesystem::create_directories(fullPath);
                } catch (const std::exception& e) {
                    Log::error("Failed to create directories: ", e.what());
                    return EXIT_FAILURE;
                }
			} 
			else 
				return EXIT_FAILURE;
		}

		return capture(fullPath, visualize);	
	}
	if (command == "calibrate")
	{
		return EXIT_SUCCESS;
	}
	else
	{
		logUsage(argv);
		return EXIT_FAILURE;
	}

	return EXIT_SUCCESS;
}
void logUsage(char* argv[])
{
    const std::string cmd = argv[0];
    Log::error("Usage: ", cmd, " <command> [options]\n\n",
               "Commands:\n",
               "  capture      Start recording\n",
               "  calibrate    Start calibration\n\n",
               "capture Options:\n",
               "  -p, --path <path>   (Required) Output path\n",
               "  -v, --visualize     (Optional) Enable preview");
}
